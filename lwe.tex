\section{ML Resistance of LWE Decryption Functions  (Lattice PUF)}
\label{sec:lwe}
%\textcolor{red}{This section formally defines ML resistance of strong PUFs via the notion of PAC learning and shows why LWE decryption functions are attractive for constructing post-quantum ML-resistant PUFs. In this section, we focus on passive attacks in which the attacker can observe the challenges sent to the verifier but is unable to generate challenges of his or her choice.}

\subsection{ML Resistance as Hardness of PAC Learning}
A strong PUF can be modeled as a function $f:\mathcal{C}\rightarrow \mathcal{R}$ mapping from the challenge space $\mathcal{C}$ (usually $\{0,1\}^n$) to the response space $\mathcal{R}$ (usually $\{0,1\}$).
We call $f$ the true model of a strong PUF since it captures the exact challenge-response behavior. 

ML attacks are usually performed by relying on a functional class of candidate models, collecting CRPs as the training data, and running a learning algorithm to obtain a model from the candidate class which best approximates the true model. %In addition to the approximation quality, the criteria of evaluating the effectiveness and efficiency of the learning algorithm also include the sample and time complexity. 
To claim that a strong PUF is easy to learn, one can propose a learning algorithm which finds a CRP model with good approximation quality using a small number of sample CRPs and terminates in a short time.
The converse is difficult: 
to claim that a PUF is hard to learn, one must show that all possible learning algorithms fail to provide models with good approximation quality, or they require a large number of CRPs or a long running time.

 PAC learning is a known and widely adopted framework for seeking a provable notion of ML resistance with a formal analysis of approximation quality, sample size, and time complexity\footnote{We note that other tools, in addition to PAC theory, for studying ML resistance exist, for example, statistical learning framework \cite{mohri2012foundations}.} \cite{mohri2012foundations}.
We now formalize the passive modeling attack scenario in the context of PAC learning.
A PAC-term for a true model $f$ of a strong PUF is a concept.
Denote as $\mathcal{F}$ the set of all possible PUF-realized functions (every instance of a PUF creates its unique functional mapping $f$).
The set of candidate models used in the learning algorithm is the hypothesis set $\mathcal{H}$. The goal of a learning algorithm is to select a candidate model that matches the true model well. 
Importantly, as shown later, the proof of PAC-hardness guarantees that $\mathcal{H}$ does not have to be restricted to be the same as $\mathcal{F}$ of true models.
This generalization permits a stronger \emph{representation-independent} PAC-hardness proof. While not always possible, representation-independent hardness can be proven for PAC-learning of decryption functions ensuring that no matter how powerful and expressive the chosen $\mathcal{H}$ is, PAC learning decryption function requires exponential time. 

Within the PAC model, CRPs in a training set are assumed to be independent and identically distributed (i.i.d.) under a certain distribution $\mathcal{D}$.

We say a set $\mathcal{F}$ of strong PUFs is PAC-learnable using $\mathcal{H}$, if there exists a polynomial-time algorithm $\mathcal{A}$ such that $\forall \epsilon > 0$, $\forall \delta >0$, for any fixed CRP distribution $\mathcal{D}$, and $\forall f\in\mathcal{F}$, given a training set of size $m$, $\mathcal{A}$ produces a candidate model $h\in\mathcal{H}$ with probability of, at least, $1-\delta$ such that
\begin{equation*}
\Pr_{(\mathbf{c},r)\sim\mathcal{D}}[f(\mathbf{c})\neq h(\mathbf{c})] < \epsilon.
\end{equation*}

In conclusion, our strategy is to say that a strong PUF is ML-resistant if it is not PAC-learnable (i.e., that it is PAC-hard). 
PAC-hardness implies that any successful ML attack requires at least an exponential running time. (We note that PAC theory was used in prior work on PUFs. In \cite{pac_learn_interpose_puf, tamper_proof_sunar, strong_ml_attack_ganji}, the PAC theory was used to show that some PUFs are learnable under the PAC framework. In contrast, we use the PAC framework to establish security guarantees against modeling attacks on a PUF.)

\subsection{Decryption Functions Are not PAC Learnable}
%What is critically important is that there exist functions that are known to be not PAC-learnable. 
%Specifically, a class of decryption functions of secure public-key cryptosystems is not PAC-learnable, as established by \cite{kearns1994cryptographic,klivans2006cryptographic}. 
%We outline their proof below.

A class of decryption functions of secure public-key cryptosystems has been shown to be not PAC-learnable \cite{kearns1994cryptographic,klivans2006cryptographic}. The proof is outlined below.

A public-key cryptosystem is a triple of probabilistic polynomial-time algorithms $(\Gen,\Enc,\Dec)$ such that:
(1) $\Gen$ takes $n$ as a security parameter and outputs a pair of keys $(pk,sk)$, the public and private keys respectively;
(2) $\Enc$ takes as input the public key $pk$ and encrypts a message (plaintext) $r$ to return a ciphertext $\mathbf{c} = \Enc(pk,r)$;
(3) $\Dec$ takes as input the private key $sk$ and a ciphertext $\mathbf{c}$ to decrypt a message $r = \Dec(sk,\mathbf{c})$.
We only need to discuss public-key cryptosystems encrypting $1$-bit messages ($0$ and $1$).

One of the security requirements of a public-key cryptosystem is that it is computationally infeasible for an adversary, knowing the public key $pk$ and a ciphertext $\mathbf{c}$, to recover the original message, $r$. 
This requirement can also be interpreted as the need for indistinguishability under the chosen plaintext attack (also often referred to as semantic security requirement). %\cite{katz2014introduction}. 
Given the encryption function $\Enc$ and the public key $pk$, the goal of an attacker is to devise a \emph{distinguisher} $\mathcal{A}$ to distinguish between encryption $\Enc(pk,r)$ of $r=0$ and $r=1$ with non-negligible probability:
\begin{equation*}
\abs{\Pr[\mathcal{A}(pk,\Enc(pk,0))=1] - \Pr[\mathcal{A}(pk,\Enc(pk,1))=1]}\geq \epsilon.
\end{equation*}
A cryptosystem is semantically secure if no polynomial-time attacker can correctly predict the message bit with non-negligible probability.

The connection between the above-stated security of a public-key cryptosystem and the hardness of learning a concept class associated with its decryption function was established in \cite{kearns1994cryptographic,klivans2006cryptographic}. 
The insight of \cite{kearns1994cryptographic,klivans2006cryptographic} is that PAC-learning is a natural result of the ease of encrypting messages with a  public key. 
Since the encryption function $\Enc$ and the public-key $pk$ is known, the distinguishing algorithm can sample independent training examples in the following way: (1) picking a plaintext bit $r$ uniformly randomly from $\{0,1\}$, (2) encrypting $r$ to get the ciphertext $\mathbf{c}=\Enc(pk,r)$. (We later refer to the resulting distribution of ciphertext as the "ciphertext distribution".)
Next, the distinguishing algorithm passes the set of training examples ($(\mathbf{c},r)$'s) into an algorithm for learning the decryption function $\Dec(sk,\cdot)$.
The PAC learning algorithm returns a model $h(\cdot)$ that aims to approximate $\Dec(sk,\cdot)$. 
Using $h(\cdot)$, one could distinguish between ciphertexts stemming from $r=0$ and $r=1$ with non-negligible probability. 
This would entail violating the semantic security of the cryptosystem. 
Technically, this can be summarized as follows \cite{kearns1994cryptographic,klivans2006cryptographic}.
\begin{theorem}
\label{thm:crypto_hardness}
If a public-key cryptosystem is secure against chosen plaintext attacks, then its decryption functions are not PAC-learnable (under the ciphertext input distribution).
\end{theorem}


\subsection{LWE Is Post-Quantum Secure}
\label{sec:lwe_crypto}
According to the cryptographic hardness above, decryption functions of any secure public-key cryptosystem, such as Rivest–Shamir–Adleman (RSA) and elliptic-curve cryptography, can be used to construct ML-resistant PUFs. 
However, integer-factoring-based cryptosystems, including RSA and elliptic-curve cryptography above, become insecure with the development of quantum computers. 
Among all post-quantum schemes, %\cite{bernstein2009introduction} 
the LWE cryptosystem based on hard lattice problems appears to be most promising due to its implementation efficiency and stubborn intractability since 1980s. 

A lattice $\mathcal{L}(\mathbf{V})$ in $n$ dimensions is the set of all integral linear combinations of a given basis $\mathbf{V}=\{\mathbf{v}_1,\mathbf{v}_2,\ldots, \mathbf{v}_n\}$ with $\mathbf{v}_i \in \mathbb{R}^n$:
\begin{equation*}
\mathcal{L}(\mathbf{V}) = \{a_1\mathbf{v}_1 + a_2\mathbf{v}_2+\ldots a_n\mathbf{v}_n: \: \forall a_i \in \mathbb{Z}\}.
\end{equation*}

The LWE problem is defined on the integer lattice $\mathcal{L}(\mathbf{V}) = \{(\mathbf{a},\innerprod{\mathbf{a},\mathbf{s}})\}$ with a basis $\mathbf{V}=(\mathbf{I};\mathbf{s})$, in which $\mathbf{I}$ is an $n$-dimensional identity matrix and $\mathbf{s}$ is a fixed row vector (also called the secret) in $\mathbb{Z}_q^n$.
Throughout this paper, vectors and matrices are denoted with bold symbols with dimension on superscript, which can be dropped for convenience in case of no confusion.
Unless otherwise specified, all arithmetic operations in the following discussion including additions and multiplications are performed in $\mathbb{Z}_q$, i.e. by modulo $q$.


For the lattice $\mathcal{L}(\mathbf{V})= \{(\mathbf{a},\innerprod{\mathbf{a},\mathbf{s}})\}$ with dimension $n$, integer modulus $q$ and a discrete Gaussian distribution $\bar{\Psi}_\alpha$ for noise, the LWE problem is defined as follows.
The secret vector $\mathbf{s}$ is fixed by choosing its coordinates uniformly randomly from $\mathbb{Z}_q$. 
Next $\mathbf{a}_i$'s are generated uniformly from $\mathbb{Z}_q^n$.
Together with the error terms $e_i$, we can compute $b_i = \innerprod{\mathbf{a},\mathbf{s}} + e_i$. 
Distribution of $(\mathbf{a}_i,b_i)$'s over $\mathbb{Z}_q^n\times\mathbb{Z}_q$ is called the LWE distribution $A_{\mathbf{s},\bar{\Psi}_\alpha}$.
The most important property of $A_{\mathbf{s},\bar{\Psi}_\alpha}$ is captured in the following lemma:
\begin{lemma}
\label{lem:LWE_dist}
Based on hardness assumptions of several lattice problems, the LWE distribution $A_{\mathbf{s},\bar{\Psi}_\alpha}$ of $(\mathbf{a},b)$'s is indistinguishable from a uniform distribution in $\mathbb{Z}_q^n\times\mathbb{Z}_q$.
\end{lemma}


Solving the decision version of LWE problem is to distinguish with a non-negligible advantage between samples from $A_{\mathbf{s},\bar{\Psi}_\alpha}$ and those generated uniformly from $\mathbb{Z}_q^n\times\mathbb{Z}_q$. 
This LWE problem is shown to be intractable to solve, without knowing the secret $\mathbf{s}$, based on the worst-case hardness of several lattice problems \cite{regev2009lattices}.
Errors $e$ are generated from a discrete Gaussian distribution $\bar{\Psi}_\alpha$ on $\mathbb{Z}_q$ parameterized by $\alpha >0$: sampling a continuous Gaussian random variable with mean $0$ and standard deviation $\alpha q/\sqrt{2\pi}$ and rounding it to the nearest integer in modulo $q$.  
Notice that error terms are also essential for guaranteeing the indistinguishability: without noise $(\mathbf{a},b)$ becomes deterministic and the secret $\mathbf{s}$ can be solved efficiently via Gaussian elimination methods.


We now describe a public-key cryptosystem based on the LWE problem above in \cite{brakerski2013classical}:
\begin{definition}{(LWE cryptosystem)}
\label{def:LWE_crypto}
\begin{itemize}
\item \textbf{Private key:} $\mathbf{s}$ is uniformly random in $\mathbb{Z}_q^n$ .
\item \textbf{Public key:}  $\mathbf{A}\in \mathbb{Z}_q^{m\times n}$ is uniformly random, and $\mathbf{e}\in \mathbb{Z}_q^m$ with each entry from $\bar{\Psi}_\alpha$. Public key is $(\mathbf{A},\mathbf{b}=\mathbf{A}\mathbf{s}+\mathbf{e})$.
\item \textbf{Encryption:}  $\mathbf{x}\in\{0,1\}^m$ is uniformly random. To encrypt a one-bit plaintext $r$, output ciphertext $\mathbf{c}=(\mathbf{a},b) = (\mathbf{A}^T\mathbf{x},\mathbf{b}^T\mathbf{x}+ r\floor{q/2})$.
\item \textbf{Decryption:} Decrypt the ciphertext $(\mathbf{a},b)$ to $0$ if $b-\innerprod{\mathbf{a},\mathbf{s}}$ is closer to $0$ than to $\floor{q/2}$ modulo $q$, and to $1$ otherwise. 
\end{itemize}
\end{definition}
Notice that each row in the public-key $(\mathbf{A},\mathbf{b})$ is an instance from the LWE distribution $A_{\mathbf{s},\bar{\Psi}_\alpha}$.

Correctness of the LWE cryptosystem can be easily verified: without the error terms, $b-\innerprod{\mathbf{a},\mathbf{s}}$ is either $0$ or $\floor{q/2}$, depending on the encrypted bit. 
Semantic security of the LWE cryptosystem follows directly from the indistinguishability of the LWE distribution from the uniform distribution in $\mathbb{Z}_q^n\times\mathbb{Z}_q$. 
Ciphertexts $(\mathbf{a},b)$ are either linear combinations or shifted linear combination of LWE samples, both of which are indistinguishable from the uniform distribution. 
This is true because shifting by any fixed length preserves the shape of a distribution.
Therefore, an efficient algorithm that can correctly guess the encrypted bit would be able to distinguish LWE samples from uniformly distributed samples. 
This allows \cite{regev2009lattices} to prove that:
\begin{theorem}
\label{thm:LWE_hardness}
Based on the hardness assumptions of several lattice problems, the LWE cryptosystem is secure against the chosen-plaintext attacks using both classical and quantum computers.
\end{theorem}

When the error terms $e_i$'s are introduced:
\begin{align*}
b-\innerprod{\mathbf{a},\mathbf{s}} = &\sum_{i\in S}b_i + \floor{\frac{q}{2}}r - \innerprod{\sum_{i\in S}\mathbf{a}_i,\mathbf{s}}\\
= &\sum_{i\in S}(\innerprod{\mathbf{a}_i,\mathbf{s}}+e_i) - \floor{\frac{q}{2}}r - \innerprod{\sum_{i\in S}\mathbf{a}_i,\mathbf{s}}\\
= &\floor{\frac{q}{2}}r - \sum_{i\in S}e_i,
\end{align*}
in which $S$ is the set of non-zero coordinates in $\mathbf{x}$.
For a decryption error to occur, the accumulated error $\sum_{i\in S}e_i$ must be greater than the decision threshold $\floor{q/4}$. 
The probability of the error is given by \cite{micciancio2009lattice}: 
\begin{align*}
\text{Err}_{\text{LWE}} &\approx 2(1-\Phi(\frac{q/4}{\alpha q \sqrt{m/2}/\sqrt{2\pi}})) \\
&= 2(1-\Phi(\frac{\sqrt{\pi}}{2\alpha\sqrt{m}})),
\end{align*}
in which $\Phi(\cdot)$ is the cumulative distribution function of the standard Gaussian variable. 
We later use this expression to find the practical parameters for the lattice PUF.

%\textcolor{red}{With the above, we proved ML resistance of the LWE decryption functions. As we will show in Section \ref{sec:design}, the lattice PUF directly builds upon a LWE decryption function. The above and the construction specifics in Section \ref{sec:lwe_dec} and Section \ref{sec:lfsr} together proves the ML resistance of lattice PUF.}